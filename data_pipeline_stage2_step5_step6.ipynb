{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d4fa9aa-a3c3-4126-b700-ea0c3fc1f841",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3579: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import openai\n",
    "import pickle\n",
    "import warnings\n",
    "import requests\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from typing import List\n",
    "from azureml.core import Workspace\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azureml.core.authentication import ServicePrincipalAuthentication\n",
    "\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_core.prompts import  PromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.prompts.few_shot import FewShotPromptTemplate\n",
    "\n",
    "from langchain.output_parsers import PydanticOutputParser, JsonOutputKeyToolsParser, CommaSeparatedListOutputParser\n",
    "pd.set_option('display.max_rows', None)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a2aad92-0a20-4bd1-9491-938076e8385f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BearerAuth(requests.auth.AuthBase):\n",
    "    def __init__(self, token):\n",
    "        self.token = token\n",
    "    def __call__(self, r):\n",
    "        r.headers[\"authorization\"] = \"Bearer \" + self.token\n",
    "        return r\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "def initialize_llm(model_name) -> AzureChatOpenAI:\n",
    "    ws = Workspace.from_config()\n",
    "    keyvault = ws.get_default_keyvault()\n",
    "    credential = DefaultAzureCredential()\n",
    "    workspacename = keyvault.get_secret(\"project-workspace-name\")\n",
    "    access_token = credential.get_token(\"https://cognitiveservices.azure.com/.default\")\n",
    "    os.environ[\"AZURE_OPENAI_KEY\"] = access_token.token\n",
    "    openai.api_type = \"azure_ad\"\n",
    "    os.environ[\"AZURE_OPENAI_ENDPOINT\"] = f\"https://{workspacename}openai.openai.azure.com/\"\n",
    "    openai.api_version = \"2023-07-01-preview\"\n",
    "    subscriptionId = keyvault.get_secret(\"project-subscription-id\")\n",
    "    # Ensure you have these environment variables set up with your Azure OpenAI credentials\n",
    "    os.environ[\"AZURE_OPENAI_API_KEY\"] = \"ee0dd46654bd4427ba4f5580b5a0db0a\"\n",
    "    os.environ[\"AZURE_OPENAI_API_BASE\"] = \"https://xqrojjmb2wjlqopopenai.openai.azure.com/\"\n",
    "\n",
    "    if model_name == \"gpt-4o\":\n",
    "        os.environ[\"AZURE_OPENAI_API_VERSION\"] = \"2024-05-01-preview\"\n",
    "        os.environ[\"AZURE_OPENAI_DEPLOYMENT_NAME\"] = \"gpt-4o\"\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "        subscriptionId = keyvault.get_secret(\"project-subscription-id\")\n",
    "        apiVersion = \"2023-10-01-preview\"\n",
    "        url = f\"https://management.azure.com/subscriptions/{subscriptionId}/resourceGroups/{workspacename}-common/providers/Microsoft.CognitiveServices/accounts/{workspacename}openai/deployments?api-version={apiVersion}\"\n",
    "        accessToken = credential.get_token(\"https://management.azure.com/.default\")\n",
    "        response = requests.get(url, auth=BearerAuth(accessToken.token));\n",
    "    \n",
    "        print(f'Initializing Model : {os.environ[\"AZURE_OPENAI_DEPLOYMENT_NAME\"]}')\n",
    "        model = AzureChatOpenAI(\n",
    "                    deployment_name=os.environ[\"AZURE_OPENAI_DEPLOYMENT_NAME\"],\n",
    "                    azure_endpoint=os.environ[\"AZURE_OPENAI_API_BASE\"],\n",
    "                    openai_api_version=os.environ[\"AZURE_OPENAI_API_VERSION\"],\n",
    "                    openai_api_key=os.environ[\"AZURE_OPENAI_API_KEY\"],\n",
    "                    max_tokens=4000,\n",
    "                    temperature=0.9,\n",
    "                    model_kwargs={\"seed\": 1337}\n",
    "                )\n",
    "        \n",
    "        print(f'Model {model_name} Initialized')\n",
    "\n",
    "    elif model_name == \"gpt-4.1\":\n",
    "\n",
    "        os.environ[\"AZURE_OPENAI_API_VERSION\"] = \"2024-12-01-preview\"\n",
    "        os.environ[\"AZURE_OPENAI_DEPLOYMENT_NAME\"] = \"gpt-4.1\"\n",
    "    \n",
    "    \n",
    "        subscriptionId = keyvault.get_secret(\"project-subscription-id\")\n",
    "        apiVersion = \"2024-12-01-preview\"\n",
    "        url = f\"https://management.azure.com/subscriptions/{subscriptionId}/resourceGroups/{workspacename}-common/providers/Microsoft.CognitiveServices/accounts/{workspacename}openai/deployments?api-version={apiVersion}\"\n",
    "        accessToken = credential.get_token(\"https://management.azure.com/.default\")\n",
    "        response = requests.get(url, auth=BearerAuth(accessToken.token));\n",
    "    \n",
    "        print(f'Initializing Model : {os.environ[\"AZURE_OPENAI_DEPLOYMENT_NAME\"]}')\n",
    "        model = AzureChatOpenAI(\n",
    "                    deployment_name=os.environ[\"AZURE_OPENAI_DEPLOYMENT_NAME\"],\n",
    "                    azure_endpoint=os.environ[\"AZURE_OPENAI_API_BASE\"],\n",
    "                    openai_api_version=os.environ[\"AZURE_OPENAI_API_VERSION\"],\n",
    "                    openai_api_key=os.environ[\"AZURE_OPENAI_API_KEY\"],\n",
    "                    max_tokens=4000,\n",
    "                    temperature=0.9,\n",
    "                    model_kwargs={\"seed\": 1337}\n",
    "                )\n",
    "        \n",
    "        print(f'Model {model_name} Initialized')\n",
    "        \n",
    "    \n",
    "    return model        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4fd3c616-020a-4dd4-8f75-ec1de1761ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_query_for_specialty_layman(model : AzureChatOpenAI, search_query : str):\n",
    "\n",
    "\n",
    "    class SpecialtiesResponse(BaseModel):\n",
    "        queries: List[str] = Field(description=\"List of queries corresponding to user provided medical specialty\")\n",
    "\n",
    "    # Set up the PydanticOutputParser with the SpecialtiesResponse model\n",
    "    output_parser = CommaSeparatedListOutputParser()\n",
    "\n",
    "    system_prompt =    \"\"\"You are a helpful AI assistant specializing in healthcare. \n",
    "                        Your task is to paraphrase the web search queries provided by the user into 5 different ways. Please make sure that the queries\n",
    "                        are of high quality and semantically represent the original query provided by the user.\n",
    "                        \n",
    "                        \n",
    "                        PLEASE TAKE YOUR TIME IN UNDERSTANDING THE USER QUERY AND THEN GENERATE POSSIBLE PARAPHRASED AUGMENTED SEARCH QUERIES WHILE\n",
    "                        RESPECTING THE ABOVE DEFINED CONDITION.\n",
    "                        \n",
    "                        PLEASE ONLY OUTPUT THE PARAPHRASED AUGMENTED SEARCH QUERIES NO OTHER TEXT.\n",
    "                        \n",
    "                        Format Instructions:\n",
    "                        {format_instructions}\n",
    "                        \n",
    "                        search_query: {search_query}\"\"\"\n",
    "    \n",
    "    # Feedback : limit the number of words between 3 to 7\n",
    "\n",
    "    # Define the prompt template\n",
    "    prompt_template = PromptTemplate.from_template(\n",
    "        template=system_prompt\n",
    "    )\n",
    "    \n",
    "    \n",
    "    chain = prompt_template | model | output_parser\n",
    "    result = chain.invoke(input={\"search_query\": search_query, \"format_instructions\" : output_parser.get_format_instructions()})\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "744e3c44-4f6d-428a-9cb9-6cba276d92a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_query_classified_specialty_filtered_diagnostic_dataset(dataset_path : str) -> dict:\n",
    "\n",
    "    \n",
    "    all_files = [dataset_path + file for file in os.listdir(dataset_path) if '.json' in file]\n",
    "\n",
    "    specialty_query_dict = {}\n",
    "\n",
    "\n",
    "    for file_path in all_files:\n",
    "        with open(file_path,'r') as file:\n",
    "            data = json.load(file)\n",
    "            \n",
    "        specialty = list(data.keys())[0]\n",
    "        queries = list(data.values())[0]\n",
    "\n",
    "        specialty_query_dict[specialty] = queries\n",
    "    \n",
    "    return specialty_query_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "94b9fddf-d0da-47e5-a957-4d0f9220feee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Syenthetic Queries Dataset Size : 590\n",
      "UES Queries Dataset Size : 553\n",
      "Verifying UES labeled Specialties exist in NUCC specialty list : True\n"
     ]
    }
   ],
   "source": [
    "dataset_path_synthetic = '../../../datasets/datasets_augmented/augmentation_set3/gpt41_query_clasification_results/'\n",
    "\n",
    "synthetic_specialty_query_dict = load_query_classified_specialty_filtered_diagnostic_dataset(dataset_path = dataset_path_synthetic)\n",
    "\n",
    "print(f'Syenthetic Queries Dataset Size : {len(synthetic_specialty_query_dict)}')\n",
    "\n",
    "dataset_path_ues = '../../../datasets/datasets_augmented/augmentation_set3/ues_keyword_nucc_classification/nucc_classification_by_specialties/'\n",
    "\n",
    "ues_specialty_query_dict = load_query_classified_specialty_filtered_diagnostic_dataset(dataset_path = dataset_path_ues)\n",
    "\n",
    "print(f'UES Queries Dataset Size : {len(ues_specialty_query_dict)}')\n",
    "\n",
    "all_specialties_ues = list(ues_specialty_query_dict.keys())\n",
    "all_specialties_synthetic_nucc = list(synthetic_specialty_query_dict.keys())\n",
    "print(f'Verifying UES labeled Specialties exist in NUCC specialty list : {True if len(set(all_specialties_ues).intersection(set(all_specialties_synthetic_nucc))) > 0 else False}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324cd391-5140-4c27-92bf-c34633b07022",
   "metadata": {},
   "source": [
    "# Find Distinct UES Queries In Each Specialty Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d8fed2fa-95b9-4a98-aa8d-8204e5669abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from typing import Dict, List, Set, Tuple\n",
    "sys.path.append('./')\n",
    "from Query_Diversity_Selection_Algorithm import QueryDiversitySelector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6410a450-d7ab-4dea-8435-44e7abb2316f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_diverse_queries_by_specialty(load_unique_queries : bool, specialty_query_dict_queries_only : Dict[str, List[str]]):\n",
    "\n",
    "    if load_unique_queries:\n",
    "\n",
    "        with open('./similarity_results.json', 'r') as file:\n",
    "            similarity_results = json.load(file)\n",
    "\n",
    "        return similarity_results\n",
    "\n",
    "    else:\n",
    "        \n",
    "    \n",
    "        embedding_model = '../../../../shekhar_tanwar/ICD-ICD-Triplet/model/NovaSearch_stella_en_1.5B_v5/'\n",
    "    \n",
    "        selector = QueryDiversitySelector(embedding_model = embedding_model)\n",
    "    \n",
    "        # run both algorithms\n",
    "    \n",
    "        # if it throws an error, use k_cluster = None\n",
    "    \n",
    "        similarity_results, cluster_results = selector.run_comparison(specialty_queries = specialty_query_dict_queries_only, similarity_threshold = 0.9, k_clusters = None)\n",
    "        with open('./similarity_results.json','w') as file:\n",
    "            json.dump(similarity_results, file, indent = 4)\n",
    "        \n",
    "        return similarity_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "196db879-60d1-437c-9789-eb5df6e7653b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "load_unique_queries = True\n",
    "similarity_results = get_diverse_queries_by_specialty(load_unique_queries = load_unique_queries,  specialty_query_dict_queries_only = ues_specialty_query_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7876b6fa-affb-4ed4-9686-6b55e44c0f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_specialties = list(similarity_results.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ccef3f23-c060-4f7f-a0b2-db3e002ac583",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "553"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_specialties)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70dae334-197e-4b06-831a-e1c467daaafb",
   "metadata": {},
   "source": [
    "# Paraphrase Distinct UES Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c9f237ea-0779-40cf-959b-187e090bb7e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_specialty_paraphrased_queries(load_paraphrased_result : bool, similarity_results : Dict[str, List[str]]):\n",
    "\n",
    "\n",
    "    if load_paraphrased_result:\n",
    "        with open('./specialty_paraphrased_queries_dict.json','r') as file:\n",
    "            specialty_paraphrased_queries_dict = json.load(file)\n",
    "        \n",
    "        return specialty_paraphrased_queries_dict, _\n",
    "\n",
    "    else:\n",
    "\n",
    "        model = initialize_llm(model_name=\"gpt-4.1\")\n",
    "    \n",
    "        specialty_paraphrased_queries_dict = {}\n",
    "        error_specialty_paraphrased_queries_dict = {}\n",
    "        \n",
    "        \n",
    "        for specialty, queries in tqdm(similarity_results.items()):\n",
    "        \n",
    "            if len(queries) == 0:\n",
    "                specialty_paraphrased_queries_dict[specialty] = []\n",
    "                continue\n",
    "        \n",
    "        \n",
    "            else:\n",
    "        \n",
    "                print(f'Generating Papraphrased Queries for Specialty : {specialty}')\n",
    "        \n",
    "                paraphrased_queries_list = []\n",
    "                error_list = []\n",
    "                for search_query in queries:\n",
    "                    try:\n",
    "                        result = get_query_for_specialty_layman(model = model, search_query = search_query)\n",
    "                        paraphrased_queries_list = paraphrased_queries_list + result\n",
    "                    except:\n",
    "                        error_list.append(search_query)\n",
    "        \n",
    "                specialty_paraphrased_queries_dict[specialty] = paraphrased_queries_list\n",
    "                error_specialty_paraphrased_queries_dict[specialty] = error_list\n",
    "\n",
    "        # these are the paraphrased production queries by each specialty\n",
    "        with open('./specialty_paraphrased_queries_dict.json','w') as file:\n",
    "            json.dump(specialty_paraphrased_queries_dict, file, indent = 4)\n",
    "            \n",
    "        return specialty_paraphrased_queries_dict , error_specialty_paraphrased_queries_dict\n",
    "        \n",
    "load_paraphrased_result = True                    \n",
    "specialty_paraphrased_queries_dict, error_specialty_paraphrased_queries_dict =  get_specialty_paraphrased_queries(load_paraphrased_result = load_paraphrased_result, similarity_results = similarity_results)          "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf04c87-30c5-4b9f-9915-faceecabf84e",
   "metadata": {},
   "source": [
    "# Generating Summary Stats For Adding Paraphrased Production Queries To Synthetic Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "92e87993-f67c-445e-8fac-20da2dda4ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_summary_stats(specialty_paraphrased_queries_dict : Dict[str, List[str]], ues_specialty_query_dict : Dict[str, List[str]] ) -> pd.DataFrame:\n",
    "\n",
    "    all_specialties_paraphrased = list(specialty_paraphrased_queries_dict.keys())\n",
    "    total_queries = []\n",
    "    \n",
    "    for specialty, queries in specialty_paraphrased_queries_dict.items():\n",
    "        paraphrased_queries = specialty_paraphrased_queries_dict.get(specialty)\n",
    "        total_queries.append(len(paraphrased_queries))\n",
    "    paraphrased_queries_stats = pd.DataFrame(list(zip(all_specialties_paraphrased, total_queries)), columns = ['Specialties','Total_Queries_Synthetic'])    \n",
    "    \n",
    "    \n",
    "    all_specialties_synthetic = list(ues_specialty_query_dict.keys())\n",
    "    \n",
    "    total_queries = []\n",
    "    \n",
    "    for specialty, queries in ues_specialty_query_dict.items():\n",
    "        synthetic_queries = ues_specialty_query_dict.get(specialty)\n",
    "        total_queries.append(len(synthetic_queries))\n",
    "    synthetic_queries_stats = pd.DataFrame(list(zip(all_specialties_synthetic, total_queries)), columns = ['Specialties','Total_Queries_Paraphrased'])    \n",
    "    \n",
    "    \n",
    "    final_stats = pd.merge(synthetic_queries_stats, paraphrased_queries_stats, how = 'left', left_on = ['Specialties'], right_on = ['Specialties'])\n",
    "    \n",
    "    final_stats = final_stats.fillna(0)\n",
    "    final_stats['Total_Queries'] = final_stats['Total_Queries_Synthetic'] + final_stats['Total_Queries_Paraphrased']\n",
    "\n",
    "    return final_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8fd7d097-bff7-4bfa-a5e6-b08a38dcd93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_stats = get_summary_stats(specialty_paraphrased_queries_dict = specialty_paraphrased_queries_dict, ues_specialty_query_dict = ues_specialty_query_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ddd45d12-dc89-4084-9921-b4e2a4cfc33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# to remove\n",
    "# ambulance\n",
    "# art therapist\n",
    "# case managercare coordinator\n",
    "# doula_doula\t\n",
    "# drama therapist\n",
    "# indian\n",
    "# \n",
    "\n",
    "final_stats_less_200_diagnostic_quries = final_stats[final_stats['Total_Queries'] < 250]\n",
    "final_stats_less_200_diagnostic_quries['Specialties_Trimmed'] = final_stats_less_200_diagnostic_quries['Specialties'].apply(lambda x : x.split('_')[0])\n",
    "final_stats_less_200_diagnostic_quries = final_stats_less_200_diagnostic_quries[~final_stats_less_200_diagnostic_quries['Specialties_Trimmed'].isin(['ambulance','art therapist','case managercare coordinator','drama therapist','indian'])]\n",
    "final_stats_less_200_diagnostic_quries = final_stats_less_200_diagnostic_quries[~final_stats_less_200_diagnostic_quries['Specialties_Trimmed'].str.contains('indian')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eeb275c7-4c7a-4440-ab92-e71b5c3fcdc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Specialties</th>\n",
       "      <th>Total_Queries_Synthetic</th>\n",
       "      <th>Total_Queries_Paraphrased</th>\n",
       "      <th>Total_Queries</th>\n",
       "      <th>Specialties_Trimmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>acupuncturist_acupuncturist</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>acupuncturist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>advanced practice midwife_advanced practice mi...</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>advanced practice midwife</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>allergy &amp; immunology_allergy &amp; immunology</td>\n",
       "      <td>38</td>\n",
       "      <td>30</td>\n",
       "      <td>68</td>\n",
       "      <td>allergy &amp; immunology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>allergy &amp; immunology_clinical &amp; laboratory imm...</td>\n",
       "      <td>41</td>\n",
       "      <td>30</td>\n",
       "      <td>71</td>\n",
       "      <td>allergy &amp; immunology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>anesthesiology_anesthesiology</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>anesthesiology</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Specialties  Total_Queries_Synthetic  \\\n",
       "0                        acupuncturist_acupuncturist                        0   \n",
       "1  advanced practice midwife_advanced practice mi...                        3   \n",
       "2          allergy & immunology_allergy & immunology                       38   \n",
       "4  allergy & immunology_clinical & laboratory imm...                       41   \n",
       "8                      anesthesiology_anesthesiology                        5   \n",
       "\n",
       "   Total_Queries_Paraphrased  Total_Queries        Specialties_Trimmed  \n",
       "0                          0              0              acupuncturist  \n",
       "1                          5              8  advanced practice midwife  \n",
       "2                         30             68       allergy & immunology  \n",
       "4                         30             71       allergy & immunology  \n",
       "8                          5             10             anesthesiology  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_stats_less_200_diagnostic_quries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8faa56aa-b37a-4dc6-8070-6771764b916f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(488, 5)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_stats_less_200_diagnostic_quries.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1c8c18e4-178d-460c-ae15-c2216c977c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_stats_less_200_diagnostic_quries.to_csv('./final_stats_less_200_diagnostic_quries.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dbbfa10-2ade-47a6-b269-8f0825ea5a88",
   "metadata": {},
   "source": [
    "## NOTE : these are those specialties for which the number of queries after diagnotic filter with addition of paraphrased production queries would be less than 250"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87192c6-00de-4c69-af29-80ecea5bd74a",
   "metadata": {},
   "source": [
    "# Feedback : \n",
    "\n",
    "Regenerate Diagnostic Queries (using Stage_2_step1_query_generator_07142025.py ) for the Specialties_Subspecialties (total 116) identified in final_stats_zero_diagnostic_quries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7de662f5-d39f-4627-8dd3-a708ba950621",
   "metadata": {},
   "outputs": [],
   "source": [
    "focus_list = list(final_stats_zero_diagnostic_quries['Specialties'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "07a90454-8ba5-41a0-9193-a752676510f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('specialty_focus_list.pkl','wb') as file:\n",
    "    pickle.dump(focus_list, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0b528adf-dcb6-4640-a9c2-bbd441366190",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "116"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(focus_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b63c8c46-7141-48f9-8d3b-b3f467be4880",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from pathlib import Path\n",
    "# import shutil\n",
    "\n",
    "# # Define source and destination folders\n",
    "# source_folder = Path(\"../../../datasets/datasets_augmented/augmentation_set3/\")\n",
    "# destination_folder = Path(\"../../../datasets/datasets_augmented/augmentation_set3/iteration1/\")\n",
    "\n",
    "# # Define the file extension to move\n",
    "# extension = \"*.json\"  # Example: move all .jpg files\n",
    "\n",
    "# # Create the destination folder if it doesn't exist\n",
    "# destination_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# # Iterate and move files\n",
    "# for file_path in source_folder.glob(extension):\n",
    "#     try:\n",
    "#         shutil.move(file_path, destination_folder / file_path.name)\n",
    "#         print(f\"Moved: {file_path.name}\")\n",
    "#     except shutil.Error as e:\n",
    "#         print(f\"Error moving {file_path.name}: {e}\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"An unexpected error occurred while moving {file_path.name}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1f27b6-1f92-401c-8a03-c687858740aa",
   "metadata": {},
   "source": [
    "# Adding Synthetic Queries and Paraphrased Production Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a39860b6-5ddf-4d7d-ba30-4e416a9d428a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "579fd318-7dd3-40ed-978e-e6640bb683fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_synthetic_queries():\n",
    "\n",
    "    path = '../../../datasets/datasets_augmented/augmentation_set4/iteration1/'\n",
    "    all_files = [path + file for file in os.listdir(path) if '.json' in file]    \n",
    "   \n",
    "    \n",
    "    specialty_query_dict = {}\n",
    "    for file_path in all_files:\n",
    "        with open(file_path, 'r') as file:\n",
    "            data_specialty = json.load(file)\n",
    "    \n",
    "        specialty = list(data_specialty.keys())[0]\n",
    "        queries = list(data_specialty.values())[0]\n",
    "    \n",
    "        specialty_query_dict[specialty] = queries\n",
    "\n",
    "    return specialty_query_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8bfc4ef9-9e7e-4eac-84f9-e10c4b79f7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_paraphrased_production_queries():\n",
    "\n",
    "    file_path = './specialty_paraphrased_queries_dict.json'\n",
    "\n",
    "    with open(file_path, 'r')  as file:\n",
    "        paraphrased_production_queries = json.load(file)\n",
    "\n",
    "    return paraphrased_production_queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7cd3f7b8-a9c3-474b-aa04-6823de47420d",
   "metadata": {},
   "outputs": [],
   "source": [
    "specialty_query_dict = get_synthetic_queries()\n",
    "paraphrased_production_queries = get_paraphrased_production_queries()\n",
    "final_stats = get_summary_stats(specialty_paraphrased_queries_dict = specialty_query_dict, ues_specialty_query_dict = paraphrased_production_queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3f81a9-f0a5-43e8-8000-e494e2ee053b",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "fa9ca7e2-e1db-4d2a-b9a7-b5b12ac4e3d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Specialties</th>\n",
       "      <th>Total_Queries_Paraphrased</th>\n",
       "      <th>Total_Queries_Synthetic</th>\n",
       "      <th>Total_Queries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>acupuncturist_acupuncturist</td>\n",
       "      <td>0</td>\n",
       "      <td>310.0</td>\n",
       "      <td>310.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>advanced practice midwife_advanced practice mi...</td>\n",
       "      <td>5</td>\n",
       "      <td>396.0</td>\n",
       "      <td>401.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>allergy &amp; immunology_allergy &amp; immunology</td>\n",
       "      <td>30</td>\n",
       "      <td>379.0</td>\n",
       "      <td>409.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>allergy &amp; immunology_allergy</td>\n",
       "      <td>80</td>\n",
       "      <td>382.0</td>\n",
       "      <td>462.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>allergy &amp; immunology_clinical &amp; laboratory imm...</td>\n",
       "      <td>30</td>\n",
       "      <td>376.0</td>\n",
       "      <td>406.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ambulance_air transport</td>\n",
       "      <td>0</td>\n",
       "      <td>374.0</td>\n",
       "      <td>374.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ambulance_land transport</td>\n",
       "      <td>0</td>\n",
       "      <td>356.0</td>\n",
       "      <td>356.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>anesthesiology_addiction medicine</td>\n",
       "      <td>75</td>\n",
       "      <td>397.0</td>\n",
       "      <td>472.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>anesthesiology_anesthesiology</td>\n",
       "      <td>5</td>\n",
       "      <td>354.0</td>\n",
       "      <td>359.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>anesthesiology_critical care medicine</td>\n",
       "      <td>55</td>\n",
       "      <td>360.0</td>\n",
       "      <td>415.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Specialties  \\\n",
       "0                        acupuncturist_acupuncturist   \n",
       "1  advanced practice midwife_advanced practice mi...   \n",
       "2          allergy & immunology_allergy & immunology   \n",
       "3                       allergy & immunology_allergy   \n",
       "4  allergy & immunology_clinical & laboratory imm...   \n",
       "5                            ambulance_air transport   \n",
       "6                           ambulance_land transport   \n",
       "7                  anesthesiology_addiction medicine   \n",
       "8                      anesthesiology_anesthesiology   \n",
       "9              anesthesiology_critical care medicine   \n",
       "\n",
       "   Total_Queries_Paraphrased  Total_Queries_Synthetic  Total_Queries  \n",
       "0                          0                    310.0          310.0  \n",
       "1                          5                    396.0          401.0  \n",
       "2                         30                    379.0          409.0  \n",
       "3                         80                    382.0          462.0  \n",
       "4                         30                    376.0          406.0  \n",
       "5                          0                    374.0          374.0  \n",
       "6                          0                    356.0          356.0  \n",
       "7                         75                    397.0          472.0  \n",
       "8                          5                    354.0          359.0  \n",
       "9                         55                    360.0          415.0  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_stats.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "31fd9b27-8959-45a0-b67d-4d02676bb1ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Specialties</th>\n",
       "      <th>Total_Queries_Paraphrased</th>\n",
       "      <th>Total_Queries_Synthetic</th>\n",
       "      <th>Total_Queries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>emergency medicine_medical toxicology</td>\n",
       "      <td>133</td>\n",
       "      <td>0.0</td>\n",
       "      <td>133.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>psychiatry &amp; neurology_brain injury medicine</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Specialties  Total_Queries_Paraphrased  \\\n",
       "147         emergency medicine_medical toxicology                        133   \n",
       "416  psychiatry & neurology_brain injury medicine                         10   \n",
       "\n",
       "     Total_Queries_Synthetic  Total_Queries  \n",
       "147                      0.0          133.0  \n",
       "416                      0.0           10.0  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_stats[final_stats['Total_Queries_Synthetic'] == min(final_stats['Total_Queries_Synthetic'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "cdc44e6e-d6a0-468a-b2e6-e4bf71a960d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Specialties</th>\n",
       "      <th>Total_Queries_Paraphrased</th>\n",
       "      <th>Total_Queries_Synthetic</th>\n",
       "      <th>Total_Queries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>emergency medicine_medical toxicology</td>\n",
       "      <td>133</td>\n",
       "      <td>0.0</td>\n",
       "      <td>133.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>psychiatry &amp; neurology_brain injury medicine</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Specialties  Total_Queries_Paraphrased  \\\n",
       "147         emergency medicine_medical toxicology                        133   \n",
       "416  psychiatry & neurology_brain injury medicine                         10   \n",
       "\n",
       "     Total_Queries_Synthetic  Total_Queries  \n",
       "147                      0.0          133.0  \n",
       "416                      0.0           10.0  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_stats[final_stats['Total_Queries_Synthetic'] < 200]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6871f2d-50f2-49d6-a0bf-00df49419498",
   "metadata": {},
   "source": [
    "# Feedback:\n",
    "emergency medicine_medical toxicology and psychiatry & neurology_brain injury medicine have 0 synthetic queries.\n",
    "\n",
    "\n",
    "Considering augmentation_set3/gpt41_query_clasification_results for adding additional queries \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "29cf83ce-b79e-4df8-8183-f3726d5185a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../../datasets/datasets_augmented/augmentation_set3/gpt41_query_clasification_results/emergency medicine_medical toxicology.json', 'r') as file:\n",
    "    em_mt = json.load(file)\n",
    "\n",
    "with open('../../../datasets/datasets_augmented/augmentation_set3/gpt41_query_clasification_results/psychiatry & neurology_brain injury medicine.json', 'r') as file:\n",
    "    pn_nbim = json.load(file)\n",
    "\n",
    "specialty_query_dict['emergency medicine_medical toxicology'] = em_mt['emergency medicine_medical toxicology']\n",
    "specialty_query_dict['psychiatry & neurology_brain injury medicine'] = pn_nbim['psychiatry & neurology_brain injury medicine']        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c42e72d8-7209-47e1-99c9-708714ddae3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_stats = get_summary_stats(specialty_paraphrased_queries_dict = specialty_query_dict, ues_specialty_query_dict = paraphrased_production_queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8d224cb7-feb9-44d1-beb6-4d82cb805015",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Specialties</th>\n",
       "      <th>Total_Queries_Paraphrased</th>\n",
       "      <th>Total_Queries_Synthetic</th>\n",
       "      <th>Total_Queries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>acupuncturist_acupuncturist</td>\n",
       "      <td>0</td>\n",
       "      <td>310</td>\n",
       "      <td>310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>advanced practice midwife_advanced practice mi...</td>\n",
       "      <td>5</td>\n",
       "      <td>396</td>\n",
       "      <td>401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>allergy &amp; immunology_allergy &amp; immunology</td>\n",
       "      <td>30</td>\n",
       "      <td>379</td>\n",
       "      <td>409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>allergy &amp; immunology_allergy</td>\n",
       "      <td>80</td>\n",
       "      <td>382</td>\n",
       "      <td>462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>allergy &amp; immunology_clinical &amp; laboratory imm...</td>\n",
       "      <td>30</td>\n",
       "      <td>376</td>\n",
       "      <td>406</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Specialties  \\\n",
       "0                        acupuncturist_acupuncturist   \n",
       "1  advanced practice midwife_advanced practice mi...   \n",
       "2          allergy & immunology_allergy & immunology   \n",
       "3                       allergy & immunology_allergy   \n",
       "4  allergy & immunology_clinical & laboratory imm...   \n",
       "\n",
       "   Total_Queries_Paraphrased  Total_Queries_Synthetic  Total_Queries  \n",
       "0                          0                      310            310  \n",
       "1                          5                      396            401  \n",
       "2                         30                      379            409  \n",
       "3                         80                      382            462  \n",
       "4                         30                      376            406  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "090c3947-0240-4c1b-a991-5da3608da485",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Specialties</th>\n",
       "      <th>Total_Queries_Paraphrased</th>\n",
       "      <th>Total_Queries_Synthetic</th>\n",
       "      <th>Total_Queries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>radiologic technologist_nuclear medicine techn...</td>\n",
       "      <td>10</td>\n",
       "      <td>232</td>\n",
       "      <td>242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Specialties  \\\n",
       "462  radiologic technologist_nuclear medicine techn...   \n",
       "\n",
       "     Total_Queries_Paraphrased  Total_Queries_Synthetic  Total_Queries  \n",
       "462                         10                      232            242  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_stats[final_stats['Total_Queries_Synthetic'] == min(final_stats['Total_Queries_Synthetic'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f77e98e-ad5e-4120-bd84-e4af20b073bc",
   "metadata": {},
   "source": [
    "# Combine and Sample Queries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "94ea46df-8a86-4e7c-830c-0ea7c7262fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "def get_synthetic_queries():\n",
    "    \"\"\"Load synthetic queries from JSON files\"\"\"\n",
    "    path = '../../../datasets/datasets_augmented/augmentation_set4_v40/iteration1/'\n",
    "    all_files = [path + file for file in os.listdir(path) if '.json' in file]\n",
    "    \n",
    "    specialty_query_dict = {}\n",
    "    for file_path in all_files:\n",
    "        with open(file_path, 'r') as file:\n",
    "            data_specialty = json.load(file)\n",
    "            \n",
    "        specialty = list(data_specialty.keys())[0]\n",
    "        queries = list(data_specialty.values())[0]\n",
    "        \n",
    "        specialty_query_dict[specialty] = queries\n",
    "    \n",
    "    return specialty_query_dict\n",
    "\n",
    "def get_paraphrased_production_queries():\n",
    "    \"\"\"Load paraphrased queries from JSON file\"\"\"\n",
    "    file_path = './specialty_paraphrased_queries_dict.json'\n",
    "    \n",
    "    with open(file_path, 'r') as file:\n",
    "        paraphrased_production_queries = json.load(file)\n",
    "    \n",
    "    return paraphrased_production_queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "825aba0c-3837-4d7b-8a40-c7f913c8f0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_summary_stats(specialty_query_dict, paraphrased_production_queries):\n",
    "    \"\"\"\n",
    "    Generate summary statistics based on the loaded query dictionaries.\n",
    "    Uses specialty_query_dict keys as reference since it has more specialties.\n",
    "    \"\"\"\n",
    "    stats_data = []\n",
    "    \n",
    "    for specialty in specialty_query_dict.keys():\n",
    "        # Count synthetic queries\n",
    "        synthetic_count = len(specialty_query_dict[specialty])\n",
    "        \n",
    "        # Count paraphrased queries (may not exist for all specialties)\n",
    "        paraphrased_count = len(paraphrased_production_queries.get(specialty, []))\n",
    "        \n",
    "        # Total queries\n",
    "        total_count = synthetic_count + paraphrased_count\n",
    "        \n",
    "        stats_data.append({\n",
    "            'Specialties': specialty,\n",
    "            'Total_Queries_Paraphrased': paraphrased_count,\n",
    "            'Total_Queries_Synthetic': synthetic_count,\n",
    "            'Total_Queries': total_count\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(stats_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "307b859b-2756-4578-b05c-c71fda4b7a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_queries_per_specialty(df, target_queries_per_specialty=250, paraphrased_threshold=50):\n",
    "    \"\"\"\n",
    "    Sample queries with preference for paraphrased queries based on specified rules.\n",
    "    \n",
    "    Rules:\n",
    "    1. Target: 250 queries per specialty\n",
    "    2. If paraphrased <= 50: take all paraphrased, fill remaining with synthetic\n",
    "    3. If total available < 250: use all queries (no sampling)\n",
    "    4. If paraphrased = 0: sample only from synthetic\n",
    "    5. If paraphrased > 200: give equal weight to both types\n",
    "    6. Otherwise: prioritize paraphrased, fill remaining with synthetic\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with columns ['Specialties', 'Total_Queries_Paraphrased', 'Total_Queries_Synthetic', 'Total_Queries']\n",
    "        target_queries_per_specialty: Target number of queries per specialty (default: 250)\n",
    "        paraphrased_threshold: Threshold for taking all paraphrased queries (default: 50)\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with sampling results\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        specialty = row['Specialties']\n",
    "        paraphrased_count = int(row['Total_Queries_Paraphrased'])\n",
    "        synthetic_count = int(row['Total_Queries_Synthetic'])\n",
    "        total_available = int(row['Total_Queries'])\n",
    "        \n",
    "        # Initialize sampling counts\n",
    "        sampled_paraphrased = 0\n",
    "        sampled_synthetic = 0\n",
    "        sampling_strategy = \"\"\n",
    "        \n",
    "        # Rule 3: If total available < target, use all queries\n",
    "        if total_available < target_queries_per_specialty:\n",
    "            sampled_paraphrased = paraphrased_count\n",
    "            sampled_synthetic = synthetic_count\n",
    "            sampling_strategy = \"Use all available (insufficient total)\"\n",
    "            \n",
    "        # Rule 4: If no paraphrased queries, sample only from synthetic\n",
    "        elif paraphrased_count == 0:\n",
    "            sampled_synthetic = min(target_queries_per_specialty, synthetic_count)\n",
    "            sampling_strategy = \"Synthetic only (no paraphrased available)\"\n",
    "            \n",
    "        # Rule 2: If paraphrased <= threshold, take all paraphrased\n",
    "        elif paraphrased_count <= paraphrased_threshold:\n",
    "            sampled_paraphrased = paraphrased_count\n",
    "            remaining_needed = target_queries_per_specialty - sampled_paraphrased\n",
    "            sampled_synthetic = min(remaining_needed, synthetic_count)\n",
    "            sampling_strategy = f\"All paraphrased + synthetic (paraphrased <= {paraphrased_threshold})\"\n",
    "            \n",
    "        # Rule 5: If paraphrased > 200, give equal weight\n",
    "        elif paraphrased_count > 200:\n",
    "            target_each = target_queries_per_specialty // 2  # 125 each\n",
    "            sampled_paraphrased = min(target_each, paraphrased_count)\n",
    "            sampled_synthetic = min(target_each, synthetic_count)\n",
    "            \n",
    "            # If one type has fewer than target_each, allocate remaining to the other\n",
    "            total_so_far = sampled_paraphrased + sampled_synthetic\n",
    "            if total_so_far < target_queries_per_specialty:\n",
    "                remaining = target_queries_per_specialty - total_so_far\n",
    "                if sampled_paraphrased < target_each:\n",
    "                    # Synthetic was limited, try to get more paraphrased\n",
    "                    additional_paraphrased = min(remaining, paraphrased_count - sampled_paraphrased)\n",
    "                    sampled_paraphrased += additional_paraphrased\n",
    "                else:\n",
    "                    # Paraphrased was limited, try to get more synthetic\n",
    "                    additional_synthetic = min(remaining, synthetic_count - sampled_synthetic)\n",
    "                    sampled_synthetic += additional_synthetic\n",
    "            \n",
    "            sampling_strategy = \"Equal weight (paraphrased > 200)\"\n",
    "            \n",
    "        # Rule 6: Default case - prioritize paraphrased, fill with synthetic\n",
    "        else:\n",
    "            # Prioritize paraphrased - aim for about 70% if possible\n",
    "            preferred_paraphrased = min(\n",
    "                int(target_queries_per_specialty * 0.7),\n",
    "                paraphrased_count\n",
    "            )\n",
    "            sampled_paraphrased = preferred_paraphrased\n",
    "            remaining_needed = target_queries_per_specialty - sampled_paraphrased\n",
    "            sampled_synthetic = min(remaining_needed, synthetic_count)\n",
    "            \n",
    "            # If we still need more and have more paraphrased available\n",
    "            total_so_far = sampled_paraphrased + sampled_synthetic\n",
    "            if total_so_far < target_queries_per_specialty and paraphrased_count > sampled_paraphrased:\n",
    "                additional_needed = target_queries_per_specialty - total_so_far\n",
    "                additional_paraphrased = min(additional_needed, paraphrased_count - sampled_paraphrased)\n",
    "                sampled_paraphrased += additional_paraphrased\n",
    "            \n",
    "            sampling_strategy = \"Prioritize paraphrased, fill with synthetic\"\n",
    "        \n",
    "        total_sampled = sampled_paraphrased + sampled_synthetic\n",
    "        paraphrased_ratio = sampled_paraphrased / total_sampled if total_sampled > 0 else 0\n",
    "        \n",
    "        results.append({\n",
    "            'Specialties': specialty,\n",
    "            'Original_Paraphrased': paraphrased_count,\n",
    "            'Original_Synthetic': synthetic_count,\n",
    "            'Original_Total': total_available,\n",
    "            'Sampled_Paraphrased': sampled_paraphrased,\n",
    "            'Sampled_Synthetic': sampled_synthetic,\n",
    "            'Total_Sampled': total_sampled,\n",
    "            'Paraphrased_Ratio': round(paraphrased_ratio, 3),\n",
    "            'Sampling_Strategy': sampling_strategy,\n",
    "            'Target_Met': total_sampled == target_queries_per_specialty\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b39571a-6658-44e2-a5af-a0bf0fa374a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_actual_samples(sampling_results, paraphrased_production_queries, specialty_query_dict):\n",
    "    \"\"\"\n",
    "    Generate actual query samples based on the sampling strategy.\n",
    "    \n",
    "    Args:\n",
    "        sampling_results: Results from sample_queries_per_specialty function\n",
    "        paraphrased_production_queries: Dictionary with paraphrased queries by specialty\n",
    "        specialty_query_dict: Dictionary with synthetic queries by specialty\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with sampled queries by specialty\n",
    "    \"\"\"\n",
    "    sampled_queries = {}\n",
    "    \n",
    "    for _, row in sampling_results.iterrows():\n",
    "        specialty = row['Specialties']\n",
    "        n_paraphrased = row['Sampled_Paraphrased']\n",
    "        n_synthetic = row['Sampled_Synthetic']\n",
    "        \n",
    "        specialty_samples = {\n",
    "            'paraphrased': [],\n",
    "            'synthetic': [],\n",
    "            'total_count': row['Total_Sampled']\n",
    "        }\n",
    "        \n",
    "        # Sample paraphrased queries\n",
    "        if n_paraphrased > 0 and specialty in paraphrased_production_queries:\n",
    "            available_paraphrased = paraphrased_production_queries[specialty]\n",
    "            if len(available_paraphrased) >= n_paraphrased:\n",
    "                specialty_samples['paraphrased'] = np.random.choice(\n",
    "                    available_paraphrased, \n",
    "                    size=n_paraphrased, \n",
    "                    replace=False\n",
    "                ).tolist()\n",
    "            else:\n",
    "                specialty_samples['paraphrased'] = available_paraphrased\n",
    "        \n",
    "        # Sample synthetic queries\n",
    "        if n_synthetic > 0 and specialty in specialty_query_dict:\n",
    "            available_synthetic = specialty_query_dict[specialty]\n",
    "            if len(available_synthetic) >= n_synthetic:\n",
    "                specialty_samples['synthetic'] = np.random.choice(\n",
    "                    available_synthetic, \n",
    "                    size=n_synthetic, \n",
    "                    replace=False\n",
    "                ).tolist()\n",
    "            else:\n",
    "                specialty_samples['synthetic'] = available_synthetic\n",
    "        \n",
    "        sampled_queries[specialty] = specialty_samples\n",
    "    \n",
    "    return sampled_queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "92b388cc-6f99-46ea-bb8b-040ef5838348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data:\n",
      "- Total specialties in synthetic data: 594\n",
      "- Total specialties in paraphrased data: 553\n",
      "- Specialties with both types: 551\n",
      "- Specialties with only synthetic: 43\n",
      "\n",
      "Sampling Results:\n",
      "\n",
      "Summary:\n",
      "Total specialties: 594\n",
      "Specialties meeting target (250): 593\n",
      "Average paraphrased ratio: 0.108\n",
      "Specialties with no paraphrased queries: 165\n",
      "Specialties with >200 paraphrased queries: 16\n",
      "\n",
      "Generating actual query samples...\n",
      "\n",
      "Saving results...\n",
      "Results saved to:\n",
      "- sampling_results.csv: Detailed sampling statistics\n",
      "- sampled_queries.json: Actual sampled queries by specialty\n"
     ]
    }
   ],
   "source": [
    "specialty_query_dict = get_synthetic_queries()\n",
    "paraphrased_production_queries = get_paraphrased_production_queries()\n",
    "\n",
    "# Get summary statistics using your actual data\n",
    "final_stats = get_summary_stats(specialty_query_dict, paraphrased_production_queries)\n",
    "\n",
    "print(f\"Loaded data:\")\n",
    "print(f\"- Total specialties in synthetic data: {len(specialty_query_dict)}\")\n",
    "print(f\"- Total specialties in paraphrased data: {len(paraphrased_production_queries)}\")\n",
    "print(f\"- Specialties with both types: {len(set(specialty_query_dict.keys()) & set(paraphrased_production_queries.keys()))}\")\n",
    "print(f\"- Specialties with only synthetic: {len(set(specialty_query_dict.keys()) - set(paraphrased_production_queries.keys()))}\")\n",
    "print()\n",
    "\n",
    "# Apply sampling algorithm\n",
    "sampling_results = sample_queries_per_specialty(final_stats, target_queries_per_specialty=250)\n",
    "\n",
    "# Display results\n",
    "print(\"Sampling Results:\")\n",
    "#print(\"=\" * 120)\n",
    "#print(sampling_results.to_string(index=False))\n",
    "\n",
    "# Summary statistics\n",
    "print(f\"\\nSummary:\")\n",
    "print(f\"Total specialties: {len(sampling_results)}\")\n",
    "print(f\"Specialties meeting target (250): {sampling_results['Target_Met'].sum()}\")\n",
    "print(f\"Average paraphrased ratio: {sampling_results['Paraphrased_Ratio'].mean():.3f}\")\n",
    "print(f\"Specialties with no paraphrased queries: {(sampling_results['Original_Paraphrased'] == 0).sum()}\")\n",
    "print(f\"Specialties with >200 paraphrased queries: {(sampling_results['Original_Paraphrased'] > 200).sum()}\")\n",
    "\n",
    "# Generate actual samples\n",
    "print(\"\\nGenerating actual query samples...\")\n",
    "sampled_queries = generate_actual_samples(sampling_results, paraphrased_production_queries, specialty_query_dict)\n",
    "\n",
    "# Save results\n",
    "print(\"\\nSaving results...\")\n",
    "sampling_results.to_csv('sampling_results.csv', index=False)\n",
    "with open('../../../datasets/datasets_augmented/final_dataset_v40/sampled_queries.json', 'w') as f:\n",
    "    json.dump(sampled_queries, f, indent=2)\n",
    "\n",
    "print(\"Results saved to:\")\n",
    "print(\"- sampling_results.csv: Detailed sampling statistics\")\n",
    "print(\"- sampled_queries.json: Actual sampled queries by specialty\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "61565c94-5c26-4c1f-a563-f2d17c17e767",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_queries_by_specialty(sampled_queries : dict):\n",
    "    \n",
    "    all_specialties = list(sampled_queries.keys())\n",
    "\n",
    "    specialty_query_dict = {}\n",
    "\n",
    "    for specialty in all_specialties:\n",
    "\n",
    "        paraphrased_queries = sampled_queries.get(specialty).get('paraphrased')\n",
    "        synthetic_queries = sampled_queries.get(specialty).get('synthetic')\n",
    "        final_queries = paraphrased_queries + synthetic_queries\n",
    "\n",
    "        specialty_query_dict[specialty] = final_queries\n",
    "\n",
    "    return specialty_query_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6b61159b-bdd5-4295-95ce-f893f17687bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "specialty_query_dict = flatten_queries_by_specialty(sampled_queries = sampled_queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d86d5b8d-9382-419c-8e79-6d7439260f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_specialties = list(specialty_query_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c7505b9e-eb36-49e7-8b09-3db5f08c7be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../../datasets/datasets_augmented/final_dataset_v40/final_dataset_v40.json', 'w') as f:\n",
    "    json.dump(specialty_query_dict, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0b35b921-4ed5-4208-87db-1e0e26c604c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_input_data(input_file, output_dir, num_chunks):\n",
    "    \n",
    "    splits_dir = f\"{output_dir}splits/\"\n",
    "    all_file_paths = [splits_dir + file for file in splits_dir if 'json' in file]\n",
    "    if len(all_file_paths) == num_chunks:\n",
    "        all_split_files = []\n",
    "        \n",
    "        for input_file in all_file_paths:\n",
    "            with open(input_file, 'r') as f:\n",
    "                specialty_data = json.load(f)\n",
    "            \n",
    "            all_split_files.append(specialty_data)\n",
    "            \n",
    "    else:\n",
    "    \n",
    "        # Create output directory\n",
    "        splits_dir = f\"{output_dir}splits/\"\n",
    "        os.makedirs(splits_dir, exist_ok=True)\n",
    "\n",
    "        # Load input data\n",
    "        with open(input_file, 'r') as f:\n",
    "            specialty_data = json.load(f)\n",
    "\n",
    "        # Get list of specialties\n",
    "        specialties = list(specialty_data.keys())\n",
    "        chunk_size = len(specialties) // num_chunks + (1 if len(specialties) % num_chunks else 0)\n",
    "\n",
    "        all_split_files = []\n",
    "        # Create chunks\n",
    "        for i in range(num_chunks):\n",
    "            start_idx = i * chunk_size\n",
    "            end_idx = min(start_idx + chunk_size, len(specialties))\n",
    "\n",
    "            chunk_specialties = specialties[start_idx:end_idx]\n",
    "            chunk_data = {specialty: specialty_data[specialty] for specialty in chunk_specialties}\n",
    "\n",
    "            # Save chunk\n",
    "            chunk_file = f\"{splits_dir}gpt_specialties_split_{i}.json\"\n",
    "            all_split_files.append(chunk_data)\n",
    "            with open(chunk_file, 'w') as f:\n",
    "                json.dump(chunk_data, f, indent=4)\n",
    "\n",
    "            #print(f\"Chunk {i}: {len(chunk_specialties)} specialties, saved to {chunk_file}\")\n",
    "\n",
    "    return all_split_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cf8e8fd0-a7da-4f7c-b8a6-d26074bd2376",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = '../../../datasets/datasets_augmented/final_dataset_v40/final_dataset_v40.json'\n",
    "output_dir = '../../../datasets/datasets_augmented/final_dataset_v40/splits/'\n",
    "    \n",
    "num_chunks = 4\n",
    "file_index = 0\n",
    "    \n",
    "\n",
    "all_split_files = split_input_data(input_file, output_dir, num_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9d7a4f-51f6-4fd0-84c0-e2cf8b1636a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 - SDK v2",
   "language": "python",
   "name": "python310-sdkv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
